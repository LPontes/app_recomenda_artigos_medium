{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time\n",
    "import tqdm\n",
    "import re\n",
    "\n",
    "import bs4 \n",
    "import glob\n",
    "import json\n",
    "\n",
    "pd.set_option(\"max.columns\", 131)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "#https://strftime.org/\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "source": [
    "# Read the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1155, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = pd.read_csv('artigos_medium_classificados.csv', sep = ',', dtype = {'author_url':str}).dropna(subset = ['classificacao', 'author_url'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "155.0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.classificacao.sum()"
   ]
  },
  {
   "source": [
    "# Pre-processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df.date, format = '%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.claps = df.claps.str.replace(r'[Kk]', 'e3',regex = True,).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title = df.title.str.replace(r'[\\xa0]', '',regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title = df.title.str.replace(r'\\W', ' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Implementing an Autoencoder in PyTorch'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df.title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author_name'] = df.author_url.apply(lambda x: x.split('/@')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns = ['classificacao', 'author_url'])\n",
    "y = df['classificacao'].copy()\n"
   ]
  },
  {
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^a-zA-z0-9]\",\" \", unidecode(text))\n",
    "    clean_tokens = []\n",
    "    \n",
    "    tokens = word_tokenize(text, language='portuguese')\n",
    "    tokens = [w for w in tokens if w not in stopwords.words(\"portuguese\")]\n",
    "    lemmatizer = RSLPStemmer()\n",
    "        \n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.stem(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "title_train = X_train['title']\n",
    "title_test = X_test['title']\n",
    "\n",
    "title_vec = TfidfVectorizer(min_df=2, ngram_range=(1,2))\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_val = title_vec.transform(title_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((577, 728), (578, 728), (577,), (578,))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "X_train_title = hstack([X_train[['claps', 'responses']], title_bow_train])\n",
    "X_test_title = hstack([X_test[['claps', 'responses']], title_bow_val])\n",
    "X_train_title.shape, X_test_title.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "source": [
    "## Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=6, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "mdl_rf = RandomForestClassifier(n_estimators=1000, random_state=0, min_samples_leaf=1, class_weight=\"balanced\", n_jobs=6)\n",
    "mdl_rf.fit(X_train_title, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf = mdl_rf.predict_proba(X_test_title)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.2493791837273932, 0.6974339484168589)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "average_precision_score(y_test, p_rf), roc_auc_score(y_test, p_rf)"
   ]
  },
  {
   "source": [
    "## LGBM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [0.08265121231498246, 7, 1, 0.7251351011494334, 0.07547006552546137, 839, 2, 2]\n",
    "lr = params[0]\n",
    "max_depth = params[1]\n",
    "min_child_samples = params[2]\n",
    "subsample = params[3]\n",
    "colsample_bytree = params[4]\n",
    "n_estimators = params[5]\n",
    "\n",
    "min_df = params[6]\n",
    "ngram_range = (1, params[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_val = title_vec.transform(title_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((577, 728), (578, 728), (577,), (578,))"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "X_train_title = hstack([X_train[['claps', 'responses']], title_bow_train])\n",
    "X_test_title = hstack([X_test[['claps', 'responses']], title_bow_val])\n",
    "X_train_title.shape, X_test_title.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mdl_lgbm = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                     min_child_samples=min_child_samples, subsample=subsample,\n",
    "                     colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                     class_weight=\"balanced\", n_jobs=6)\n",
    "mdl_lgbm.fit(X_train_title, y_train)\n",
    "\n",
    "p_lgbm = mdl_lgbm.predict_proba(X_test_title)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.18187582043339956, 0.5788163136925981)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "average_precision_score(y_test, p_lgbm), roc_auc_score(y_test, p_lgbm)"
   ]
  },
  {
   "source": [
    "## Logistic regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('maxabsscaler', MaxAbsScaler(copy=True)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.5, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=6, penalty='l2',\n",
       "                                    random_state=0, solver='lbfgs', tol=0.0001,\n",
       "                                    verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "Xtrain_wtitle2 = csr_matrix(X_train_title.copy())\n",
    "Xval_wtitle2 = csr_matrix(X_test_title.copy())\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler = MaxAbsScaler()\n",
    "\n",
    "#Xtrain_wtitle2[:, :2] = scaler.fit_transform(Xtrain_wtitle2[:, :2].todense())\n",
    "#Xval_wtitle2[:, :2] = scaler.transform(Xval_wtitle2[:, :2].todense())\n",
    "#Xtrain_wtitle2 = scaler.fit_transform(Xtrain_wtitle2)\n",
    "#Xval_wtitle2 = scaler.transform(Xval_wtitle2)\n",
    "\n",
    "lr_pipeline = make_pipeline(MaxAbsScaler(), LogisticRegression(C=0.5, penalty='l2',n_jobs=6, random_state=0))\n",
    "lr_pipeline.fit(Xtrain_wtitle2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lr = lr_pipeline.predict_proba(Xval_wtitle2)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.2621203517936057, 0.6937513105472846)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "average_precision_score(y_test, p_lr), roc_auc_score(y_test, p_lr)"
   ]
  },
  {
   "source": [
    "## Ensemble"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.23829788441295843, 0.68536380792619)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "p = (p_lr + p_rf + p_lgbm)/3\n",
    "average_precision_score(y_test, p), roc_auc_score(y_test, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            LR        RF      LGBM\n",
       "LR    1.000000  0.803908  0.482546\n",
       "RF    0.803908  1.000000  0.575971\n",
       "LGBM  0.482546  0.575971  1.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LR</th>\n      <th>RF</th>\n      <th>LGBM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LR</th>\n      <td>1.000000</td>\n      <td>0.803908</td>\n      <td>0.482546</td>\n    </tr>\n    <tr>\n      <th>RF</th>\n      <td>0.803908</td>\n      <td>1.000000</td>\n      <td>0.575971</td>\n    </tr>\n    <tr>\n      <th>LGBM</th>\n      <td>0.482546</td>\n      <td>0.575971</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "pd.DataFrame({\"LR\": p_lr, \"RF\": p_rf, \"LGBM\": p_lgbm}).corr()"
   ]
  },
  {
   "source": [
    "p = 0.5*p_rf + 0.5*p_lgbm\n",
    "average_precision_score(y_test, p), roc_auc_score(y_test, p)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.22637550181919064, 0.6743552107360034)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ]
  },
  {
   "source": [
    "## Salvar modelos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../prod/title_vectorizer_20210302.pkl.z']"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "jb.dump(mdl_lgbm, \"../prod/lgbm_20210302.pkl.z\")\n",
    "jb.dump(mdl_rf, \"../prod/random_forest_20210302.pkl.z\")\n",
    "jb.dump(lr_pipeline, \"../prod/logistic_reg_20210302.pkl.z\")\n",
    "jb.dump(title_vec, \"../prod/title_vectorizer_20210302.pkl.z\")"
   ]
  }
 ]
}